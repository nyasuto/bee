name: ğŸ§ª Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # æ¯æ—¥åˆå‰3æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
    - cron: '0 3 * * *'

env:
  GO_VERSION: '1.21'

jobs:
  # ===== ãƒãƒ«ãƒOSãƒ»ãƒãƒ«ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ =====
  multi-platform-test:
    name: ğŸŒ Multi-Platform Tests
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        go-version: ['1.20', '1.21', '1.22']
        exclude:
          # Windows + Go 1.20 ã®çµ„ã¿åˆã‚ã›ã‚’é™¤å¤–ï¼ˆäº’æ›æ€§å•é¡Œï¼‰
          - os: windows-latest
            go-version: '1.20'
            
    runs-on: ${{ matrix.os }}
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ğŸ¹ Setup Go ${{ matrix.go-version }}
      uses: actions/setup-go@v4
      with:
        go-version: ${{ matrix.go-version }}
        
    - name: ğŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ matrix.go-version }}-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-${{ matrix.go-version }}-
          ${{ runner.os }}-go-
          
    - name: ğŸ”§ Install dependencies
      run: go mod download
      
    - name: ğŸ—ï¸ Build project
      run: go build -v ./...
      
    - name: ğŸ§ª Run unit tests
      run: |
        go test -v -race -coverprofile=coverage.out ./...
        
    - name: ğŸ“Š Generate coverage report
      if: matrix.os == 'ubuntu-latest' && matrix.go-version == '1.21'
      run: |
        go tool cover -html=coverage.out -o coverage.html
        go tool cover -func=coverage.out > coverage.txt
        
    - name: ğŸ“¤ Upload coverage reports
      if: matrix.os == 'ubuntu-latest' && matrix.go-version == '1.21'
      uses: actions/upload-artifact@v3
      with:
        name: coverage-reports
        path: |
          coverage.out
          coverage.html
          coverage.txt
        retention-days: 30
        
    - name: ğŸ¯ Test CLI functionality
      shell: bash
      run: |
        # ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªã®ãƒ†ã‚¹ãƒˆ
        if [ "${{ matrix.os }}" = "windows-latest" ]; then
          BINARY="./bin/bee.exe"
        else
          BINARY="./bin/bee"
        fi
        
        # MakefileãŒã‚ã‚Œã°ä½¿ç”¨ã€ãªã‘ã‚Œã°ç›´æ¥ãƒ“ãƒ«ãƒ‰
        if [ -f "Makefile" ]; then
          make build
        else
          mkdir -p bin
          if [ "${{ matrix.os }}" = "windows-latest" ]; then
            go build -o bin/bee.exe ./cmd/bee
          else
            go build -o bin/bee ./cmd/bee
          fi
        fi
        
        # CLIãƒ˜ãƒ«ãƒ—ãƒ†ã‚¹ãƒˆ
        if [ -f "$BINARY" ]; then
          echo "âœ… CLI binary built successfully"
          $BINARY help || echo "Help command test completed"
        else
          echo "âš ï¸ CLI binary not found, skipping CLI tests"
        fi

  # ===== ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ =====
  benchmark-test:
    name: âš¡ Benchmark Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ğŸ¹ Setup Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        
    - name: ğŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-bench-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-bench-
          
    - name: ğŸ”§ Install dependencies
      run: go mod download
      
    - name: âš¡ Run benchmarks
      run: |
        echo "## âš¡ Benchmark Results" > benchmark_results.md
        echo "\`\`\`" >> benchmark_results.md
        go test -bench=. -benchmem -count=3 ./... | tee -a benchmark_results.md
        echo "\`\`\`" >> benchmark_results.md
        
    - name: ğŸ“Š Analyze benchmark results
      run: |
        echo "" >> benchmark_results.md
        echo "## ğŸ“Š Performance Analysis" >> benchmark_results.md
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤ãƒã‚§ãƒƒã‚¯
        echo "### ğŸ¯ Performance Thresholds" >> benchmark_results.md
        
        # Phase 1 ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã®æœŸå¾…æ€§èƒ½
        if grep -q "BenchmarkPerceptron/Forward" benchmark_results.md; then
          FORWARD_TIME=$(grep "BenchmarkPerceptron/Forward" benchmark_results.md | awk '{print $3}' | head -1)
          echo "- **Forward Propagation**: $FORWARD_TIME (target: <100ns/op)" >> benchmark_results.md
        fi
        
        if grep -q "BenchmarkPerceptron/Training" benchmark_results.md; then
          TRAINING_TIME=$(grep "BenchmarkPerceptron/Training" benchmark_results.md | awk '{print $3}' | head -1)
          echo "- **Training**: $TRAINING_TIME (target: <50Î¼s/op)" >> benchmark_results.md
        fi
        
        echo "" >> benchmark_results.md
        echo "### ğŸ’¡ Optimization Notes" >> benchmark_results.md
        echo "- Forward propagation should be <100ns/op for real-time inference" >> benchmark_results.md
        echo "- Training should be <50Î¼s/op for large dataset handling" >> benchmark_results.md
        echo "- Memory allocations should be minimized (0 allocs/op preferred)" >> benchmark_results.md
        
    - name: ğŸ“¤ Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark_results.md
        retention-days: 30

  # ===== çµ±åˆãƒ†ã‚¹ãƒˆ =====
  integration-test:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ğŸ¹ Setup Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        
    - name: ğŸ”§ Install dependencies
      run: go mod download
      
    - name: ğŸ—ï¸ Build CLI tool
      run: |
        if [ -f "Makefile" ]; then
          make build
        else
          mkdir -p bin
          go build -o bin/bee ./cmd/bee
        fi
        
    - name: ğŸ§ª Test ML pipeline integration
      run: |
        echo "## ğŸ”— Integration Test Results" > integration_results.md
        echo "" >> integration_results.md
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if [ -d "datasets" ]; then
          echo "### âœ… Dataset Integration" >> integration_results.md
          echo "Available datasets:" >> integration_results.md
          ls datasets/*.csv | while read dataset; do
            echo "- \`$(basename $dataset)\`" >> integration_results.md
          done
          echo "" >> integration_results.md
          
          # AND ã‚²ãƒ¼ãƒˆã§ã®E2Eãƒ†ã‚¹ãƒˆ
          if [ -f "datasets/and.csv" ] && [ -f "bin/bee" ]; then
            echo "### ğŸ¯ End-to-End AND Gate Test" >> integration_results.md
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
            ./bin/bee train -data datasets/and.csv -output models/test_and.json -epochs 50 -verbose 2>&1 | head -10 >> integration_results.md || true
            
            if [ -f "models/test_and.json" ]; then
              echo "âœ… Training completed successfully" >> integration_results.md
              
              # æ¨è«–ãƒ†ã‚¹ãƒˆ
              echo "" >> integration_results.md
              echo "**Inference Tests:**" >> integration_results.md
              echo "\`\`\`" >> integration_results.md
              ./bin/bee infer -model models/test_and.json -input "0,0" >> integration_results.md 2>&1 || true
              ./bin/bee infer -model models/test_and.json -input "1,1" >> integration_results.md 2>&1 || true
              echo "\`\`\`" >> integration_results.md
              
              # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
              ./bin/bee test -data datasets/and.csv -model-path models/test_and.json >> integration_results.md 2>&1 || true
              
            else
              echo "âŒ Training failed" >> integration_results.md
            fi
          fi
          
        else
          echo "### âš ï¸ No datasets found" >> integration_results.md
          echo "Integration tests require datasets directory" >> integration_results.md
        fi
        
    - name: ğŸ§  Test learning effect verification
      run: |
        echo "" >> integration_results.md
        echo "### ğŸ§  Learning Effect Verification" >> integration_results.md
        
        # Phase 1 å®Ÿè£…ãƒã‚§ãƒƒã‚¯
        if [ -d "phase1" ]; then
          echo "- âœ… Phase 1 implementation available" >> integration_results.md
          
          # ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
          if [ -f "phase1/perceptron_test.go" ]; then
            echo "- âœ… Comprehensive tests available" >> integration_results.md
            
            # XOR ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            XOR_RESULT=$(go test ./phase1 -run TestXORProblem -v 2>&1 || true)
            if echo "$XOR_RESULT" | grep -q "PASS"; then
              echo "- âœ… XOR limitation test passed" >> integration_results.md
            else
              echo "- âš ï¸ XOR test issues detected" >> integration_results.md
            fi
          fi
        else
          echo "- âš ï¸ Phase 1 not yet implemented" >> integration_results.md
        fi
        
        echo "" >> integration_results.md
        echo "### ğŸ“ˆ Learning Progress" >> integration_results.md
        echo "- **Current Phase**: Phase 1 (Perceptron)" >> integration_results.md
        echo "- **Status**: Implementation complete" >> integration_results.md
        echo "- **Next Milestone**: Phase 1.1 (MLP with backpropagation)" >> integration_results.md
        
    - name: ğŸ“¤ Upload integration results
      uses: actions/upload-artifact@v3
      with:
        name: integration-test-results
        path: integration_results.md
        retention-days: 30

  # ===== ãƒ†ã‚¹ãƒˆå›å¸°æ¤œå‡º =====
  regression-detection:
    name: ğŸ”„ Regression Detection
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - name: ğŸ“¥ Checkout PR code
      uses: actions/checkout@v4
      
    - name: ğŸ“¥ Checkout base branch
      uses: actions/checkout@v4
      with:
        ref: ${{ github.event.pull_request.base.ref }}
        path: base-branch
        
    - name: ğŸ¹ Setup Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        
    - name: ğŸ”§ Install dependencies for both versions
      run: |
        go mod download
        cd base-branch && go mod download
        
    - name: ğŸ§ª Run tests on base branch
      run: |
        cd base-branch
        echo "## ğŸ”„ Regression Test Results" > ../regression_results.md
        echo "" >> ../regression_results.md
        echo "### ğŸ“Š Base Branch Results" >> ../regression_results.md
        echo "\`\`\`" >> ../regression_results.md
        go test ./... -short 2>&1 | tee -a ../regression_results.md || true
        echo "\`\`\`" >> ../regression_results.md
        
    - name: ğŸ§ª Run tests on PR branch
      run: |
        echo "" >> regression_results.md
        echo "### ğŸ”„ PR Branch Results" >> regression_results.md
        echo "\`\`\`" >> regression_results.md
        go test ./... -short 2>&1 | tee -a regression_results.md || true
        echo "\`\`\`" >> regression_results.md
        
    - name: ğŸ“ˆ Compare results
      run: |
        echo "" >> regression_results.md
        echo "### ğŸ¯ Regression Analysis" >> regression_results.md
        
        # ç°¡å˜ãªå›å¸°ãƒã‚§ãƒƒã‚¯
        BASE_TESTS=$(cd base-branch && go test ./... -short 2>&1 | grep -c "PASS\|FAIL" || echo "0")
        PR_TESTS=$(go test ./... -short 2>&1 | grep -c "PASS\|FAIL" || echo "0")
        
        echo "- **Base branch tests**: $BASE_TESTS" >> regression_results.md
        echo "- **PR branch tests**: $PR_TESTS" >> regression_results.md
        
        if [ "$PR_TESTS" -ge "$BASE_TESTS" ]; then
          echo "- **Status**: âœ… No regression detected" >> regression_results.md
        else
          echo "- **Status**: âš ï¸ Potential regression detected" >> regression_results.md
        fi
        
        echo "" >> regression_results.md
        echo "### ğŸ’¡ Recommendations" >> regression_results.md
        echo "- Ensure all existing tests continue to pass" >> regression_results.md
        echo "- Add tests for new functionality" >> regression_results.md
        echo "- Check for performance regressions in benchmarks" >> regression_results.md
        
    - name: ğŸ“¤ Upload regression results
      uses: actions/upload-artifact@v3
      with:
        name: regression-test-results
        path: regression_results.md
        retention-days: 30

  # ===== ãƒ†ã‚¹ãƒˆçµæœçµ±åˆ =====
  test-summary:
    name: ğŸ“‹ Test Summary
    runs-on: ubuntu-latest
    needs: [multi-platform-test, benchmark-test, integration-test, regression-detection]
    if: always()
    
    steps:
    - name: ğŸ“Š Generate Test Summary
      run: |
        echo "# ğŸ§ª Testing Summary Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ“‹ Test Results" >> $GITHUB_STEP_SUMMARY
        echo "- **Multi-Platform Tests**: ${{ needs.multi-platform-test.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Benchmark Tests**: ${{ needs.benchmark-test.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Integration Tests**: ${{ needs.integration-test.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Regression Detection**: ${{ needs.regression-detection.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # å…¨ä½“çš„ãªæˆåŠŸåˆ¤å®š
        if [ "${{ needs.multi-platform-test.result }}" = "success" ] && [ "${{ needs.benchmark-test.result }}" = "success" ] && [ "${{ needs.integration-test.result }}" = "success" ]; then
          echo "## âœ… Overall Status: PASSED" >> $GITHUB_STEP_SUMMARY
          echo "All critical tests passed successfully!" >> $GITHUB_STEP_SUMMARY
        else
          echo "## âŒ Overall Status: FAILED" >> $GITHUB_STEP_SUMMARY
          echo "Some tests failed. Please review the detailed results." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ“ Artifacts Generated" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage reports (HTML & text)" >> $GITHUB_STEP_SUMMARY
        echo "- Benchmark performance analysis" >> $GITHUB_STEP_SUMMARY
        echo "- Integration test results" >> $GITHUB_STEP_SUMMARY
        echo "- Regression detection report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ¯ Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review coverage reports for completeness" >> $GITHUB_STEP_SUMMARY
        echo "- Check benchmark results for performance regressions" >> $GITHUB_STEP_SUMMARY
        echo "- Ensure integration tests cover all ML pipeline stages" >> $GITHUB_STEP_SUMMARY