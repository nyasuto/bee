# CLAUDE.md - Bee Neural Network Project Guide

Bee Go ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã® Claude Code (claude.ai/code) ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

## ğŸ¤– Project Overview

**Bee** (ğŸ) ã¯ã€ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã‹ã‚‰å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¾ã§æ®µéšçš„ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ã¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚å°ã•ãªãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆBeeï¼‰ãŒç¾¤ã‚Œã¨ã—ã¦å”èª¿ã—ã€é«˜åº¦ãªçŸ¥èƒ½ã‚’å½¢æˆã—ã¾ã™ã€‚

**Tech Stack**: Go | Makefile | CLI Tool

## ğŸš« CRITICAL: GitHub Operations Restrictions

**æœ€é‡è¦ãƒ«ãƒ¼ãƒ«: Claude Codeã¯ä»¥ä¸‹ã®æ“ä½œã‚’æ±ºã—ã¦è¡Œã£ã¦ã¯ã„ã‘ã¾ã›ã‚“**

### ğŸ”´ çµ¶å¯¾ç¦æ­¢äº‹é …
1. **Pull Requestã®ãƒãƒ¼ã‚¸** - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ãŒåˆ¤æ–­ãƒ»å®Ÿè¡Œã™ã‚‹
2. **Issueã®ã‚¯ãƒ­ãƒ¼ã‚º** - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ãŒåˆ¤æ–­ãƒ»å®Ÿè¡Œã™ã‚‹  
3. **ãƒ–ãƒ©ãƒ³ãƒã®å‰Šé™¤** - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ãŒåˆ¤æ–­ãƒ»å®Ÿè¡Œã™ã‚‹

### âœ… Claude CodeãŒå®Ÿè¡Œå¯èƒ½ãªæ“ä½œ
- ãƒªãƒªãƒ¼ã‚¹ã®ä½œæˆ
- Pull Requestã®ä½œæˆ
- Issueã®ä½œæˆ
- ãƒ–ãƒ©ãƒ³ãƒã®ä½œæˆ
- ã‚³ãƒŸãƒƒãƒˆã®ä½œæˆã¨ãƒ—ãƒƒã‚·ãƒ¥
- CI/CDã®å®Ÿè¡Œç¢ºèªï¼ˆçŠ¶æ³å ±å‘Šã®ã¿ï¼‰

**ç†ç”±**: ã“ã‚Œã‚‰ã®æ“ä½œã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ–¹å‘æ€§ã‚„å“è³ªã«é‡å¤§ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ãŸã‚ã€å¿…ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ˜ç¤ºçš„ãªåˆ¤æ–­ã¨æ‰¿èªãŒå¿…è¦ã§ã™ã€‚

## ğŸ”„ Pull Request Creation Rule

**CRITICAL: ã‚³ãƒ¼ãƒ‰å¤‰æ›´å¾Œã¯å¿…ãšPull Requestã‚’ä½œæˆã™ã‚‹**

### å¿…é ˆãƒ•ãƒ­ãƒ¼
1. ã‚³ãƒ¼ãƒ‰å¤‰æ›´å®Œäº†
2. å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ (`make quality`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
4. **Pull Requestä½œæˆ** (çµ¶å¯¾ã«å¿˜ã‚Œã¦ã¯ã„ã‘ãªã„)
5. âš ï¸ **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹æ‰¿èªãƒ»ãƒãƒ¼ã‚¸å¾…ã¡** (Claude Codeã¯ãƒãƒ¼ã‚¸ã—ãªã„)

### PRä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒå®Œäº†ã—ã¦ã„ã‚‹
- [ ] å“è³ªãƒã‚§ãƒƒã‚¯ãŒé€šã£ã¦ã„ã‚‹
- [ ] é©åˆ‡ãªãƒ–ãƒ©ãƒ³ãƒåã«ãªã£ã¦ã„ã‚‹
- [ ] PRèª¬æ˜ãŒé©åˆ‡ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹
- [ ] é–¢é€£ã™ã‚‹IssueãŒå‚ç…§ã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ‰¿èªãƒ»ãƒãƒ¼ã‚¸ã‚’ä¾é ¼

## ğŸ¯ Project Architecture

### Phase-Based Learning Structure
```
Phase 1.0: Perceptron    - ç·šå½¢åˆ†é¡ã€é‡ã¿æ›´æ–°
Phase 1.1: MLP          - å¤šå±¤ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã€èª¤å·®é€†ä¼æ’­
Phase 2.0: CNN/RNN      - ç”»åƒå‡¦ç†ã€ç³»åˆ—å‡¦ç†
Phase 3.0: Attention    - Self-Attentionã€Transformer
Phase 4.0: LLM          - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€åˆ†æ•£å­¦ç¿’
```

### Expected Directory Structure
```
bee/
â”œâ”€â”€ phase1/         # Basic perceptron implementations
â”œâ”€â”€ phase2/         # CNN, RNN implementations  
â”œâ”€â”€ phase3/         # Attention, Transformer implementations
â”œâ”€â”€ phase4/         # LLM, distributed learning
â”œâ”€â”€ cmd/            # CLI tools (bee train / bee infer)
â”œâ”€â”€ datasets/       # Dataset management
â”œâ”€â”€ benchmark/      # Performance comparison tools
â”œâ”€â”€ visualization/  # Visualization tools
â”œâ”€â”€ docs/           # Learning guides
â”œâ”€â”€ Makefile        # Build system
â””â”€â”€ go.mod          # Go module definition
```

## ğŸ›  Essential Commands

```bash
# Development Setup
make setup          # Initial project setup
make dev           # Start development environment
make install       # Install dependencies

# Quality checks
make quality       # Run all quality checks
make quality-fix   # Auto-fix issues
make lint          # Run linting
make format        # Format code
make test          # Run tests

# Build and deployment
make build         # Build for production
make clean         # Clean build artifacts
make benchmark     # Performance benchmarking

# Git workflow
make git-hooks     # Setup pre-commit hooks
make pr-ready      # Prepare for pull request
```

## ğŸ”§ Development Guidelines

### ğŸ§  å­¦ç¿’é‡è¦–å®Ÿè£…æ–¹é‡

**CRITICAL: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¾å­˜ã‚’é¿ã‘ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ¬è³ªç†è§£ã‚’æœ€å„ªå…ˆ**

#### âœ… è¨±å¯ã•ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨
```go
// åŸºæœ¬çš„ãªæ•°å€¤æ¼”ç®—ã®ã¿è¨±å¯
import "gonum.org/v1/gonum/mat"    // ç·šå½¢ä»£æ•°åŸºæœ¬æ“ä½œ
import "gonum.org/v1/gonum/stat"  // çµ±è¨ˆè¨ˆç®—åŸºæœ¬æ“ä½œ
// ä½ãƒ¬ãƒ™ãƒ« GPU bindingï¼ˆCUDA/OpenCLï¼‰
```

#### ğŸš« ç¦æ­¢ã•ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨
```go
// é«˜ãƒ¬ãƒ™ãƒ«MLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ç¦æ­¢
// âŒ import "gorgonia.org/gorgonia"     // TensorFlow like
// âŒ import "github.com/tensorflow/tfgo" // TensorFlow bindings  
// âŒ PyTorch bindings
// âŒ å®Œæˆã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
```

#### ğŸ¯ æ®µéšçš„å®Ÿè£…ãƒ«ãƒ¼ãƒ«

1. **ãƒŠã‚¤ãƒ¼ãƒ–å®Ÿè£…**: æœ€ã‚‚ç†è§£ã—ã‚„ã™ã„ç›´æ¥å®Ÿè£…ã‚’å¿…ãšæœ€åˆã«ä½œæˆ
2. **æœ€é©åŒ–å®Ÿè£…**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ï¼ˆå­¦ç¿’åŠ¹æœã¨ä¸¡ç«‹ï¼‰
3. **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¯”è¼ƒ**: è‡ªå®Ÿè£… vs æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®šé‡æ¯”è¼ƒ
4. **ç†è«–çµ±åˆ**: æ•°å¼â†’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ â†’ã‚³ãƒ¼ãƒ‰â†’ãƒ†ã‚¹ãƒˆã®å®Œå…¨ã‚µã‚¤ã‚¯ãƒ«

#### ğŸ’¡ å­¦ç¿’åŠ¹æœæœ€å¤§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
```go
// âŒ Bad: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸¸æŠ•ã’
func (nn *NeuralNet) Forward(x mat.Matrix) mat.Matrix {
    return someLibrary.Predict(x)  // å­¦ç¿’åŠ¹æœã‚¼ãƒ­
}

// âœ… Good: æ®µéšçš„ç†è§£é‡è¦–å®Ÿè£…
func (nn *NeuralNet) Forward(x []float64) []float64 {
    // Step 1: é‡ã¿ä»˜ãå’Œè¨ˆç®—ï¼ˆæ˜ç¤ºçš„å®Ÿè£…ï¼‰
    weightedSum := 0.0
    for i, weight := range nn.weights {
        weightedSum += x[i] * weight  // å„è¨ˆç®—ã‚’æ˜ç¤º
    }
    
    // Step 2: ãƒã‚¤ã‚¢ã‚¹è¿½åŠ 
    weightedSum += nn.bias
    
    // Step 3: æ´»æ€§åŒ–é–¢æ•°ï¼ˆè‡ªå®Ÿè£…ï¼‰
    return nn.sigmoid(weightedSum)  // é–¢æ•°å†…éƒ¨ã‚‚è‡ªå®Ÿè£…
}

// æ´»æ€§åŒ–é–¢æ•°ã®è‡ªå®Ÿè£…ä¾‹
func (nn *NeuralNet) sigmoid(x float64) float64 {
    // æ•°å¼: Ïƒ(x) = 1 / (1 + e^(-x))
    return 1.0 / (1.0 + math.Exp(-x))
}
```


### Go Code Styleï¼ˆå­¦ç¿’é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
```go
// Package perceptron implements basic perceptron neural network
// Mathematical Foundation: McCulloch-Pitts neuron model (1943)
// Learning Goal: Understanding linear classification and weight updates
package perceptron

import (
    "errors"
    "fmt"
    "math"
)

// Perceptron represents a basic perceptron neuron
// Mathematical Model: y = Ïƒ(wÂ·x + b) where Ïƒ is activation function
type Perceptron struct {
    weights      []float64  // synaptic weights (w)
    bias         float64    // bias term (b)
    learningRate float64    // learning rate (Î±)
}

// NewPerceptron creates a new perceptron with random weights
// Learning Rationale: Understanding initialization strategies
func NewPerceptron(inputSize int, learningRate float64) *Perceptron {
    weights := make([]float64, inputSize)
    // Xavier initialization for better convergence
    for i := range weights {
        weights[i] = (rand.Float64()*2 - 1) / math.Sqrt(float64(inputSize))
    }
    
    return &Perceptron{
        weights:      weights,
        bias:         0.0,  // Start with zero bias
        learningRate: learningRate,
    }
}

// Forward performs forward propagation
// Mathematical Foundation: y = Ïƒ(Î£(wi * xi) + b)
// Learning Goal: Understanding weighted sum and activation
func (p *Perceptron) Forward(inputs []float64) (float64, error) {
    if len(inputs) != len(p.weights) {
        return 0, errors.New("input size mismatch")
    }
    
    // Step 1: Calculate weighted sum (æ˜ç¤ºçš„å®Ÿè£…)
    weightedSum := p.bias
    for i, input := range inputs {
        weightedSum += p.weights[i] * input
    }
    
    // Step 2: Apply activation function (Heaviside step function)
    // Mathematical: Ïƒ(x) = 1 if x â‰¥ 0, else 0
    if weightedSum >= 0.0 {
        return 1.0, nil
    }
    return 0.0, nil
}

// Train performs one training iteration using perceptron learning rule
// Mathematical Foundation: Î”w = Î±(t - y)x where t=target, y=output
// Learning Goal: Understanding gradient-free weight updates
func (p *Perceptron) Train(inputs []float64, target float64) error {
    if len(inputs) != len(p.weights) {
        return errors.New("input size mismatch")
    }
    
    // Step 1: Forward propagation
    output, err := p.Forward(inputs)
    if err != nil {
        return err
    }
    
    // Step 2: Calculate error
    error := target - output
    
    // Step 3: Update weights (perceptron learning rule)
    // Mathematical: wi = wi + Î± * error * xi
    for i, input := range inputs {
        p.weights[i] += p.learningRate * error * input
    }
    
    // Step 4: Update bias
    // Mathematical: b = b + Î± * error
    p.bias += p.learningRate * error
    
    return nil
}
```

### ğŸ“ å­¦ç¿’é‡è¦–é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

1. **ç†è«–ç†è§£**: å®Ÿè£…å‰ã«æ•°å¼ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ•°å­¦çš„èƒŒæ™¯ã‚’ç†è§£
2. **ãƒŠã‚¤ãƒ¼ãƒ–å®Ÿè£…**: æœ€ã‚‚ç†è§£ã—ã‚„ã™ã„ç›´æ¥å®Ÿè£…ã‹ã‚‰é–‹å§‹
3. **ãƒ†ã‚¹ãƒˆä½œæˆ**: æ•°å€¤çš„æ­£ç¢ºæ€§ç¢ºèªã‚’å«ã‚€åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
4. **æ€§èƒ½æ¸¬å®š**: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šã¨æœ€é©åŒ–å‰å¾Œã®æ¯”è¼ƒ
5. **æœ€é©åŒ–å®Ÿè£…**: å­¦ç¿’åŠ¹æœã‚’ç¶­æŒã—ãªãŒã‚‰æ€§èƒ½æ”¹å–„
6. **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¯”è¼ƒ**: è‡ªå®Ÿè£… vs æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®šé‡è©•ä¾¡
7. **å“è³ªãƒã‚§ãƒƒã‚¯**: `make quality` ã§å“è³ªç¢ºèª
8. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: å­¦ç¿’è¦³ç‚¹ã¨æ•°å­¦çš„èƒŒæ™¯ã‚’å«ã‚€èª¬æ˜
9. **Pull Requestä½œæˆ**: å¿…ãšPRä½œæˆ

### ğŸ§ª å­¦ç¿’åŠ¹æœæ¤œè¨¼è¦ä»¶

å®Ÿè£…ã”ã¨ã«ä»¥ä¸‹ã‚’å¿…ãšå«ã‚€ï¼š

#### å¿…é ˆå®Ÿè£…è¦ç´ 
- **Mathematical Foundation**: å®Ÿè£…ã™ã‚‹æ•°å¼ã®è©³ç´°èª¬æ˜
- **Step-by-Step Implementation**: å„è¨ˆç®—ã‚¹ãƒ†ãƒƒãƒ—ã®æ˜ç¤ºçš„å®Ÿè£…
- **Learning Rationale**: å®Ÿè£…é¸æŠã®å­¦ç¿’è¦³ç‚¹èª¬æ˜
- **Numerical Validation**: æ—¢çŸ¥è§£ã¨ã®æ•°å€¤æ¯”è¼ƒãƒ†ã‚¹ãƒˆ

#### å¿…é ˆãƒ†ã‚¹ãƒˆè¦ç´ 
- **Unit Tests**: å„é–¢æ•°ã®å‹•ä½œç¢ºèª
- **Integration Tests**: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å…¨ä½“ã®å‹•ä½œç¢ºèª
- **Numerical Tests**: æ•°å­¦çš„æ­£ç¢ºæ€§ã®ç¢ºèª
- **Performance Tests**: å®Ÿè¡Œæ™‚é–“ãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
- **Comparison Tests**: ä»–å®Ÿè£…ã¨ã®çµæœæ¯”è¼ƒ

#### å¿…é ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´ 
- **Algorithm Explanation**: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å‹•ä½œåŸç†
- **Mathematical Derivation**: æ•°å¼ã®å°å‡ºéç¨‹
- **Implementation Notes**: å®Ÿè£…ä¸Šã®æ³¨æ„ç‚¹ãƒ»å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ
- **Performance Analysis**: æ€§èƒ½ç‰¹æ€§ã®åˆ†æ

## ğŸ— AI-First Design Principles

1. **Type Safety First**: Goã®å‹å®‰å…¨æ€§ã‚’æœ€å¤§é™æ´»ç”¨
2. **Modular Architecture**: ç‹¬ç«‹ã—ãŸãƒ†ã‚¹ãƒˆå¯èƒ½ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
3. **Clear Separation of Concerns**: æ©Ÿèƒ½ã®æ˜ç¢ºãªåˆ†é›¢
4. **Predictable Patterns**: ä¸€è²«ã—ãŸå‘½åã¨æ§‹é€ è¦å‰‡
5. **Self-Documenting Code**: è±Šå¯Œãªã‚³ãƒ¡ãƒ³ãƒˆã¨å‹æ³¨é‡ˆ

## ğŸ“‹ Development Checklist

æ–°æ©Ÿèƒ½å®Ÿè£…æ™‚ã«ç¢ºèªã™ã‚‹ã“ã¨:

- [ ] **Documentation**: Go docã‚³ãƒ¡ãƒ³ãƒˆè¨˜è¼‰æ¸ˆã¿
- [ ] **Testing**: å˜ä½“ãƒ†ã‚¹ãƒˆã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºä¿
- [ ] **Error Handling**: é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
- [ ] **Performance**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] **Quality Checks**: `make quality` é€šéç¢ºèª
- [ ] **Pull Request**: PRä½œæˆå®Œäº†

## ğŸ¯ Current State & Implementation Priority

**âš ï¸ Important**: ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ç¾åœ¨åˆæœŸçŠ¶æ…‹ã§ã€README.mdã®ã¿å­˜åœ¨ã—ã¾ã™ã€‚

### Implementation Priority
1. **Phase 1.0**: åŸºæœ¬ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã‹ã‚‰é–‹å§‹
2. **Build System**: Makefile ã¨ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰
3. **CLI Tool**: `bee` ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«å®Ÿè£…
4. **Progressive Implementation**: æ®µéšçš„ã«é«˜åº¦ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¸

### Performance Goals
- æ¨è«–é€Ÿåº¦: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”100å€é«˜é€ŸåŒ–
- ç²¾åº¦å‘ä¸Š: ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ ~70% â†’ LLM ~98%
- å­¦ç¿’åŠ¹ç‡: æ®µéšçš„æ§‹é€ ã«ã‚ˆã‚‹ä½“ç³»çš„ç†è§£

---

**ã“ã®ã‚¬ã‚¤ãƒ‰ã¯åŠ¹ç‡çš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºã¨é«˜ã„ã‚³ãƒ¼ãƒ‰å“è³ªç¶­æŒã‚’å®Ÿç¾ã—ã¾ã™ã€‚**